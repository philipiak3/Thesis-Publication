{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MyBri\\anaconda3\\envs\\myenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\mybri\\anaconda3\\envs\\myenv\\lib\\site-packages (0.0.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\mybri\\anaconda3\\envs\\myenv\\lib\\site-packages (from bs4) (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\mybri\\anaconda3\\envs\\myenv\\lib\\site-packages (from beautifulsoup4->bs4) (2.5)\n"
     ]
    }
   ],
   "source": [
    "pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train directories\n",
    "\n",
    "train_image_harvard_dir = \"c://Users//MyBri//OneDrive//Desktop//Masters//Dissertation//polyp detection//datasets//POLYP-DETECTION-YOLO-NASH//base-datasets//PolypsSet//train2019//Image\"\n",
    "train_annotations_harvard_dir = \"c://Users//MyBri//OneDrive//Desktop//Masters//Dissertation//polyp detection//datasets//POLYP-DETECTION-YOLO-NASH//base-datasets//PolypsSet//train2019//Annotation\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation directories\n",
    "\n",
    "valid_image_harvard_dir = r\"C:\\Users\\MyBri\\OneDrive\\Desktop\\Masters\\Dissertation\\polyp detection\\datasets\\POLYP-DETECTION-YOLO-NASH\\base-datasets\\PolypsSet\\val2019\\Image\"\n",
    "valid_annotations_harvard_dir = r\"C:\\Users\\MyBri\\OneDrive\\Desktop\\Masters\\Dissertation\\polyp detection\\datasets\\POLYP-DETECTION-YOLO-NASH\\base-datasets\\PolypsSet\\val2019\\Annotation\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test directories\n",
    "\n",
    "test_image_harvard_dir = r\"C:\\Users\\MyBri\\OneDrive\\Desktop\\Masters\\Dissertation\\polyp detection\\datasets\\POLYP-DETECTION-YOLO-NASH\\base-datasets\\PolypsSet\\test2019\\Image\"\n",
    "test_annotations_harvard_dir = r\"C:\\Users\\MyBri\\OneDrive\\Desktop\\Masters\\Dissertation\\polyp detection\\datasets\\POLYP-DETECTION-YOLO-NASH\\base-datasets\\PolypsSet\\test2019\\Annotation\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images = os.listdir(train_image_harvard_dir)\n",
    "train_annotations = os.listdir(train_annotations_harvard_dir)\n",
    "\n",
    "train_images.sort()\n",
    "train_annotations.sort()\n",
    "\n",
    "\n",
    "# Verify that the images and annotations match\n",
    "train_image_names = set([x.split(\".\")[0] for x in train_images])\n",
    "train_annotation_names = set([x.split(\".\")[0] for x in train_annotations])\n",
    "\n",
    "train_image_names == train_annotation_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_images = os.listdir(valid_image_harvard_dir)\n",
    "valid_annotations = os.listdir(valid_annotations_harvard_dir)\n",
    "\n",
    "#these dont matter\n",
    "valid_images.sort()\n",
    "valid_annotations.sort()\n",
    "\n",
    "\n",
    "# Verify that the images and annotations match\n",
    "valid_image_names = set([x.split(\".\")[0] for x in valid_images])\n",
    "valid_annotation_names = set([x.split(\".\")[0] for x in valid_annotations])\n",
    "\n",
    "valid_image_names == valid_annotation_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images = os.listdir(test_image_harvard_dir)\n",
    "test_annotations = os.listdir(test_annotations_harvard_dir)\n",
    "\n",
    "#these dont matter\n",
    "test_images.sort()\n",
    "test_annotations.sort()\n",
    "\n",
    "\n",
    "# Verify that the images and annotations match\n",
    "test_image_names = set([x.split(\".\")[0] for x in test_images])\n",
    "test_annotation_names = set([x.split(\".\")[0] for x in test_annotations])\n",
    "\n",
    "test_image_names == test_annotation_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set base directories\n",
    "\n",
    "base_target_dir = \"./PolypDetectionHarv/\"\n",
    "train_images_dir = os.path.join(base_target_dir, \"train\", \"images\")\n",
    "train_annots_dir = os.path.join(base_target_dir, \"train\", \"labels\")\n",
    "\n",
    "val_images_dir = os.path.join(base_target_dir, \"valid\", \"images\")\n",
    "val_annots_dir = os.path.join(base_target_dir, \"valid\", \"labels\")\n",
    "\n",
    "test_images_dir = os.path.join(base_target_dir, \"test\", \"images\")\n",
    "test_annots_dir = os.path.join(base_target_dir, \"test\", \"labels\")\n",
    "\n",
    "os.makedirs(train_images_dir, exist_ok=True)\n",
    "os.makedirs(train_annots_dir, exist_ok=True)\n",
    "os.makedirs(val_images_dir, exist_ok=True)\n",
    "os.makedirs(val_annots_dir, exist_ok=True)\n",
    "os.makedirs(test_images_dir, exist_ok=True)\n",
    "os.makedirs(test_annots_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28773 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28773/28773 [06:41<00:00, 71.74it/s]\n"
     ]
    }
   ],
   "source": [
    "status=\"train\"\n",
    "for train_image in tqdm(train_images):\n",
    "    # train_image = train_images[631]\n",
    "\n",
    "    # 90 - 10 split\n",
    "    #if np.random.uniform() > 0.1:\n",
    "    #    status = \"train\"\n",
    "    #else:\n",
    "    #   status = \"val\"\n",
    "\n",
    "\n",
    "    train_image_path = os.path.join(\n",
    "        train_image_harvard_dir, train_image\n",
    "        )\n",
    "    image = Image.open(train_image_path)\n",
    "    img_width, img_height = image.size\n",
    "\n",
    "    train_image_annotation = os.path.join(\n",
    "        train_annotations_harvard_dir, train_image\n",
    "        ).replace(\".jpg\", \".xml\")\n",
    "\n",
    "    # Load the annotation\n",
    "    with open(train_image_annotation) as f:\n",
    "        annotation = BeautifulSoup(f, \"xml\")\n",
    "\n",
    "    boxes = []\n",
    "\n",
    "    # Get the bbox coordinates (blank if no polyp detected)\n",
    "    xmin = annotation.find(\"xmin\")\n",
    "    if xmin is not None:\n",
    "        xmin = int(annotation.find(\"xmin\").text)\n",
    "        ymin = int(annotation.find(\"ymin\").text)\n",
    "        xmax = int(annotation.find(\"xmax\").text)\n",
    "        ymax = int(annotation.find(\"ymax\").text)\n",
    "\n",
    "        center_x = (xmin + xmax) / 2\n",
    "        center_y = (ymin + ymax) / 2\n",
    "        height = ymax - ymin\n",
    "        width = xmax - xmin\n",
    "\n",
    "        center_x /= img_width\n",
    "        center_y /= img_height\n",
    "        height /= img_height\n",
    "        width /= img_width\n",
    "\n",
    "        boxes.append([0, center_x, center_y, width, height])\n",
    "\n",
    "    if len(boxes) == 0:\n",
    "        pass\n",
    "    \n",
    "    # 1. copy the image to the train/val folder\n",
    "    new_image_name = f\"harvard__{train_image}\"\n",
    "    new_image_path = os.path.join(\n",
    "        base_target_dir, \"train\", \"images\", new_image_name\n",
    "        )\n",
    "    \n",
    "    shutil.copy(train_image_path, new_image_path)  \n",
    "    # 2. create the annotation for the image in the train/val folder\n",
    "    annotation_file_name = new_image_name.replace(\".jpg\", \".txt\")\n",
    "    annotation_file_path = os.path.join(\n",
    "        base_target_dir, \"train\", \"labels\", annotation_file_name\n",
    "        )\n",
    "    \n",
    "    with open(annotation_file_path, \"w\") as f:\n",
    "        for box in boxes:\n",
    "            f.write(\" \".join([str(x) for x in box]) + \"\\n\")\n",
    "    # 3. write the image path in the train/val.txt file\n",
    "    train_val_file_path = os.path.join(\n",
    "        base_target_dir, f\"{status}.txt\"\n",
    "        )\n",
    "    \n",
    "    with open(train_val_file_path, \"a\") as f:\n",
    "        f.write(new_image_path + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = \"valid\"\n",
    "\n",
    "# Iterate through subfolders (different file structure)\n",
    "for subfolder in os.listdir(valid_image_harvard_dir):\n",
    "    subfolder_path = os.path.join(valid_image_harvard_dir, subfolder)\n",
    "\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        \n",
    "        for image_filename in os.listdir(subfolder_path):\n",
    "            if image_filename.lower().endswith(\".jpg\"):\n",
    "                # Form the paths for the image and annotation\n",
    "                image_path = os.path.join(subfolder_path, image_filename)\n",
    "                annotation_filename = os.path.splitext(image_filename)[0] + \".xml\"\n",
    "                annotation_path = os.path.join(valid_annotations_harvard_dir, subfolder, annotation_filename)\n",
    "\n",
    "                # Check if the corresponding annotation file exists\n",
    "                if os.path.exists(annotation_path):\n",
    "                    image = Image.open(image_path)\n",
    "                    img_width, img_height = image.size\n",
    "\n",
    "                    # Load the annotation\n",
    "                    with open(annotation_path) as f:\n",
    "                        annotation = BeautifulSoup(f, \"xml\")\n",
    "\n",
    "                    boxes = []\n",
    "\n",
    "                    # Get the bbox coordinates (blank if no polyp detected)\n",
    "                    xmin = annotation.find(\"xmin\")\n",
    "                    if xmin is not None:\n",
    "                        xmin = int(annotation.find(\"xmin\").text)\n",
    "                        ymin = int(annotation.find(\"ymin\").text)\n",
    "                        xmax = int(annotation.find(\"xmax\").text)\n",
    "                        ymax = int(annotation.find(\"ymax\").text)\n",
    "\n",
    "                        center_x = (xmin + xmax) / 2\n",
    "                        center_y = (ymin + ymax) / 2\n",
    "                        height = ymax - ymin\n",
    "                        width = xmax - xmin\n",
    "\n",
    "                        center_x /= img_width\n",
    "                        center_y /= img_height\n",
    "                        height /= img_height\n",
    "                        width /= img_width\n",
    "\n",
    "                        boxes.append([0, center_x, center_y, width, height])\n",
    "\n",
    "                    if len(boxes) == 0:\n",
    "                        pass\n",
    "\n",
    "                    # 1. Copy the image to the valid/images folder\n",
    "                    new_image_name = f\"harvard__{subfolder}_{os.path.splitext(image_filename)[0]}.jpg\"\n",
    "                    new_image_path = os.path.join(base_target_dir, \"valid\", \"images\", new_image_name)\n",
    "\n",
    "                    shutil.copy(image_path, new_image_path)\n",
    "\n",
    "                    # 2. Create the annotation for the image in the valid/labels folder\n",
    "                    annotation_file_name = f\"harvard__{subfolder}_{os.path.splitext(image_filename)[0]}.txt\"\n",
    "                    annotation_file_path = os.path.join(base_target_dir, \"valid\", \"labels\", annotation_file_name)\n",
    "\n",
    "                    with open(annotation_file_path, \"w\") as f:\n",
    "                        for box in boxes:\n",
    "                            f.write(\" \".join([str(x) for x in box]) + \"\\n\")\n",
    "\n",
    "                    # 3. Write the image path in the valid.txt file\n",
    "                    valid_val_file_path = os.path.join(base_target_dir, f\"{status}.txt\")\n",
    "\n",
    "                    with open(valid_val_file_path, \"a\") as f:\n",
    "                        f.write(new_image_path + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = \"test\"\n",
    "\n",
    "# Iterate through subfolders (same structure as valid)\n",
    "for subfolder in os.listdir(test_image_harvard_dir):\n",
    "    subfolder_path = os.path.join(test_image_harvard_dir, subfolder)\n",
    "\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        # Iterate through image files inside each subfolder\n",
    "        for image_filename in os.listdir(subfolder_path):\n",
    "            if image_filename.lower().endswith(\".jpg\"):\n",
    "                # Form the paths for the image and annotation\n",
    "                image_path = os.path.join(subfolder_path, image_filename)\n",
    "                annotation_filename = os.path.splitext(image_filename)[0] + \".xml\"\n",
    "                annotation_path = os.path.join(test_annotations_harvard_dir, subfolder, annotation_filename)\n",
    "\n",
    "                # Check if the corresponding annotation file exists\n",
    "                if os.path.exists(annotation_path):\n",
    "                    image = Image.open(image_path)\n",
    "                    img_width, img_height = image.size\n",
    "\n",
    "                    # Load the annotation\n",
    "                    with open(annotation_path) as f:\n",
    "                        annotation = BeautifulSoup(f, \"xml\")\n",
    "\n",
    "                    boxes = []\n",
    "\n",
    "                    # Get the bbox coordinates (blank if no polyp detected)\n",
    "                    xmin = annotation.find(\"xmin\")\n",
    "                    if xmin is not None:\n",
    "                        xmin = int(annotation.find(\"xmin\").text)\n",
    "                        ymin = int(annotation.find(\"ymin\").text)\n",
    "                        xmax = int(annotation.find(\"xmax\").text)\n",
    "                        ymax = int(annotation.find(\"ymax\").text)\n",
    "\n",
    "                        center_x = (xmin + xmax) / 2\n",
    "                        center_y = (ymin + ymax) / 2\n",
    "                        height = ymax - ymin\n",
    "                        width = xmax - xmin\n",
    "\n",
    "                        center_x /= img_width\n",
    "                        center_y /= img_height\n",
    "                        height /= img_height\n",
    "                        width /= img_width\n",
    "\n",
    "                        boxes.append([0, center_x, center_y, width, height])\n",
    "\n",
    "                    if len(boxes) == 0:\n",
    "                        pass\n",
    "\n",
    "                    # 1. Copy the image to the valid/images folder\n",
    "                    new_image_name = f\"harvard__{subfolder}_{os.path.splitext(image_filename)[0]}.jpg\"\n",
    "                    new_image_path = os.path.join(base_target_dir, \"test\", \"images\", new_image_name)\n",
    "\n",
    "                    shutil.copy(image_path, new_image_path)\n",
    "\n",
    "                    # 2. Create the annotation for the image in the valid/labels folder\n",
    "                    annotation_file_name = f\"harvard__{subfolder}_{os.path.splitext(image_filename)[0]}.txt\"\n",
    "                    annotation_file_path = os.path.join(base_target_dir, \"test\", \"labels\", annotation_file_name)\n",
    "\n",
    "                    with open(annotation_file_path, \"w\") as f:\n",
    "                        for box in boxes:\n",
    "                            f.write(\" \".join([str(x) for x in box]) + \"\\n\")\n",
    "\n",
    "                    # 3. Write the image path in the valid.txt file\n",
    "                    test_val_file_path = os.path.join(base_target_dir, f\"{status}.txt\")\n",
    "\n",
    "                    with open(test_val_file_path, \"a\") as f:\n",
    "                        f.write(new_image_path + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
